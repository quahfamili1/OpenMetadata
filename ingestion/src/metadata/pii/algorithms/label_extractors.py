#  Copyright 2025 Collate
#  Licensed under the Collate Community License, Version 1.0 (the "License");
#  you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#  https://github.com/open-metadata/OpenMetadata/blob/main/ingestion/LICENSE
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
"""
Label extractor interface and implementations.
"""
from abc import ABC, abstractmethod
from typing import Generic, Mapping, Set, TypeVar, final

from metadata.pii.algorithms.scoring_ops import scores_cleanup, scores_to_probabilities

T = TypeVar("T")


class LabelExtractor(ABC, Generic[T]):
    """
    Protocol for extracting labels from a mapping of label scores.

    This goal is to abstract the logic of how labels are extracted
    from the scores, allowing different strategies to be implemented
    depending on the underlying algorithm or use-case.
    """

    @abstractmethod
    def extract_labels(self, scores: Mapping[T, float]) -> Set[T]:
        """
        Extract labels from the given scores mapping.

        Args:
            scores (Mapping[T, float]): A mapping from labels to scores or probabilities.

        Returns:
            Set[T]: A set of labels extracted from the scores.
        """


@final
class ProbabilisticLabelExtractor(LabelExtractor[T], Generic[T]):
    """
    Extracts the most probable label(s) from a set of raw class scores using score filtering
    and probability normalization.

    This extractor treats the input scores as representing a multiclass classification scenario,
    where only one or a few mutually exclusive labels are expected to be true. It filters out
    low-confidence scores, normalizes the remaining ones into a probability distribution, and
    returns the top-k labels that meet a minimum probability threshold.

    After normalization, scores are interpreted as probabilitiesâ€”that is, each label's
    value represents its relative likelihood among the remaining candidates.

    Args:
        k (int): The number of top labels to consider based on normalized probability.
        score_threshold (float): Minimum raw score required to keep a label before normalization.
        prob_threshold (float): Minimum normalized probability required for a label to be returned.

    Returns:
        Set[T]: A set of labels that pass both score and probability thresholds.

    Notes:
        - If only one label remains after score filtering, it will have a probability of 1.0
          and will always be returned if `k >= 1`.
        - When multiple labels remain, their probabilities may be lower, and some or all
          may fall below the `prob_threshold`.
        - This approach implicitly encodes a confidence mechanism: a label must be
          both strong enough in raw score and relatively dominant in probability to be selected.
    """

    def __init__(
        self,
        k: int,
        score_threshold: float,
        prob_threshold: float,
    ) -> None:

        if not (0 <= score_threshold <= 1):  # pylint: disable=superfluous-parens
            raise ValueError("score_threshold must be between 0 and 1")
        if not (0 <= prob_threshold <= 1):  # pylint: disable=superfluous-parens
            raise ValueError("prob_threshold must be between 0 and 1")
        if k < 1:
            raise ValueError("k must be at least 1")

        self._score_threshold = score_threshold
        self._prob_threshold = prob_threshold
        self._k = k

    def extract_labels(self, scores: Mapping[T, float]) -> Set[T]:
        """
        Applies filtering and probability-based selection to extract high-confidence labels.
        """
        filtered_scores = scores_cleanup(
            scores, min_score=self._score_threshold, max_score=1.0
        )

        probabilities = scores_to_probabilities(filtered_scores)

        if probabilities is None:
            return set()

        top_k = sorted(probabilities.items(), key=lambda item: item[1], reverse=True)[
            : self._k
        ]

        return {label for label, prob in top_k if prob >= self._prob_threshold}
